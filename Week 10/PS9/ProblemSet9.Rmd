---
title: "ProblemSet9-AnirudhPenmatcha"
output: html_document
date: "2023-11-02"
---

# Question 1 (Problem Set D)

# 1.

The measurements don't appear to be from a symmetric distribution because the values are growing towards the right. This means that the data is heavily concentrated to the right and hence it will be left skewed.


```{r}
normal <- c(4.1, 6.3, 7.8, 8.5, 8.9, 10.4, 11.5, 12.0, 13.8, 17.6, 24.3, 37.2)
diabetic <- c(11.5, 12.1, 16.1, 17.8, 24, 28.8, 33.9, 40.7, 51.3, 56.2, 61.7, 69.2)
```

For a distribution to be symmetric, their mean and median have to be close to each other 
```{r}
print(paste(mean(normal), median(normal)))
```

We can see that the mean and median are not close for the normal data. Hence it is not symmetric.

```{r}
print(paste(mean(diabetic), median(diabetic)))
```

Again, mean and median are not close. Hence, they are not symmetric

# 2.

# plotting

# plots of original data
```{r}
plot(normal)
```
```{r}
plot(diabetic)
```
# plots of data transformed with log
```{r}
plot(log(normal))
log(normal)
```

```{r}
plot(log(diabetic))
log(diabetic)
```
# plots of data transformed with square root

```{r}
plot(sqrt(normal))
sqrt(normal)
```
```{r}
plot(sqrt(diabetic))
sqrt(diabetic)
```

The plots of the data transformed with log look closer to a sample obtained from a symmetric distribution. The data transformed with square roots has one issue which is the sqrt(normal) looks less symmetric than log(normal). Hence I would prefer log transformation here. 

# 3.

```{r}
qqnorm(log(normal))
qqline(log(normal))
```

```{r}
qqnorm(log(diabetic))
qqline(log(diabetic))
```
```{r}
qqnorm(sqrt(normal))
qqline(sqrt(normal))
```
```{r}
qqnorm(sqrt(diabetic))
qqline(sqrt(diabetic))
```

The transformed measurements of log appear to be from a normal distribution more than the transformed measurements of the square root.

# 4.

We can check this by performing a hypothesis test

```{r}
t.test(log(diabetic), log(normal), alternative = "greater")
```

The p-value of 0.0004 support the alternative hypothesis and hence we can say that the patients have an increased urinary excretion

# Question 2

# a.
The problem we are working with here has provided a very small sample size which is 7. Hence, using the t-distribution becomes imperative

# b.

```{r}
delta.hat <- 68.5 - 65.5
var.male <- 3^2
var.female <- 2.5^2
SE <- sqrt(var.male/7 + var.female/7)
```

We are given the degrees of freedom as 11.6 and the value of R code qt(.975,df=11.62) as 2.187
```{r}
# confidence intervals of the t-distributions for the given samples of male and female heights

print(paste("The upper interval = ", delta.hat + 2.187 * SE, " The lower interval = ", delta.hat - 2.187 * SE))
```

# c.
We needn't conclude that there is no difference because there is a possibility for a combination where their differences in height can be 0 but also more and less than that. Generally speaking we shouldn't be hasty in jumping to conclusions in such cases especially when dealing with a small dataset. 

# Question 3

# a.
The rule for student's test is that their variances must be equal. However, we are given the SD's as 15.9 and 17.3. Meaning, variances will equal 252.81 and 299.29. Therefore, we'll need to use welch's test. 

# b.
```{r}
delta.hat <- 24.3 - 16.8
SE <- sqrt( (15.9^2)/592 + (17.3^2)/154 )
T.Welch <- delta.hat/SE
T.Welch
```

p-value
```{r}
2 * (1 - pt(abs(T.Welch), df = 225))
```

# c.

95% confidence interval 
```{r}
print(paste("The upper interval = ", delta.hat + qt(.975, df = 225) * SE, " The lower interval = ", delta.hat - qt(.975, df = 225) * SE))
```
Therefore, we can say that we are 95% confident that the average difference in weeks worked between treament and control groups is between 10.5 and 4.4. 


# Question 4

# a.

Because we are taking two samples out of one population and given that the standard deviations in the results of the two groups are not equal, it is valid to use welch's test here
```{r}
delta.hat <- 61 - 59
SE <- sqrt(((10^2)/100) + ((13^2)/100))
T.Welch <- delta.hat/SE
T.Welch
```

```{r}
df <- (((10^2)/100+(12^2)/100)^2)/ ((((10^2)/100)^2/99)+(((13^2)/100)^2/99))
```

p-value
```{r}
2 * (1 - pt(abs(T.Welch), df = df))
```


# b.

#lower interval
```{r}
delta.hat - qt(.95, df = df) * SE
```
#upper interval
```{r}
delta.hat + qt(.95, df = df) * SE
```

# c. 

I can conclude that the p-value being high enough we can accept null and reject alternative. The confidence interval is includes negative and positive values which means that there is a possibility for an increased performance when looking at their averages. However, even a decreased performance can be seen. Hence, we need a bigger sample size to work with in order to make a clearer conclusion about their average performance having increased or decreased or even remaining the same. 

# Question 5

# a. 

I would use t test here because the sample is quite small (12). The assumption made in t test is that the data follows a normal distribution. 
In test scores, generally, we can observe a normal distribution. So it does come close to satisfying the assumption of this test.


# b.

Let u be the expected change. So H0: u0 <or= 0; H1: u1 >= 0
```{r}
treatment <- c(-2.3, -0.7, -0.2, 0.1, 0.5, 0.8, 0.9, 1.6, 2.0, 3.9, 4.5, 6.0)
control <- c(-2.9, -1.5, -0.9, -0.8, -0.7, -0.5, -0.2, 0.2, 0.6, 1.2, 1.9, 2.8)
T.stat <- t.test(treatment, control, alternative = "greater")

change <- mean(treatment) - mean(control)
SE <- sqrt((var(treatment)/12) + (var(control)/12))
df <- ((var(treatment)/12+var(control)/12)^2) / (((var(treatment)/12)^2/11)+((var(control)/12)^2/11))
T.stat <- change / SE
T.stat
```

p-value
```{r}
(1 - pt(abs(T.stat), df = df))
```

# c. 

95% confidence interval
```{r}
print(paste("The upper interval = ", change + qt(.975, df = 11) * SE , " The lower interval = ", change - qt(.975, df = 11) * SE ))
```

# d.

The above information says that it's possible the mean changes in VO2 between the treatment and control groups is from -0.29 to 3.2. Although this is based on 24 patients we can say the differences will be within this range. However, it's also worth noting that the changes are not consistently positive as we can see that it will be even between 0 and -0.29 which means that there is a negative effect possible. One reason for this is that the number of experimental units is low. Perhaps having a larger group to perform this experiment on can give us an interval that is more representative of what kind of an impact whether positive or negative the aerobic exercise is having on people. 


# Question 6

# a.

The experimental unit here is a type 2 diabetes patient. The measurements taken here are of patients' glycemic index when they had only dates and when they had dates with coffee. This problem is only with one independent sample 

# b. 
The null hypothesis will be H0: u0 = 0 and H1: u0 != 0 
```{r}
t.stat <- (11.5 - 0) / (21/sqrt(10))
t.stat
```
right-tailed
```{r}
1-pt(t.stat, df = 9)
```
left-tailed
```{r}
pt(t.stat, df = 9)
```
The minimum here is right-tailed
```{r}
2*(1-pt(t.stat, df = 9))
```

The probability is decently high for us to accept null and reject alternative hypothesis

# c.

The p-value is not high enough first of all to say conclusively that dates' glycemic index changes with or without coffee. Second of all the sample size is not large enough. We need more data. 

